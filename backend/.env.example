# ============================================================================
# Babblr Environment Configuration
# ============================================================================
# For detailed documentation on all settings, see: ../ENVIRONMENT.md
#
# Quick Start:
# 1. Copy this file: cp .env.example .env (or copy .env.example .env on Windows)
# 2. Configure your LLM provider (see below)
# 3. Restart the backend
# ============================================================================

# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================
# Choose your LLM provider: ollama (default), claude, gemini, mock
# Ollama requires no API key and runs locally
LLM_PROVIDER=ollama

# --- Ollama Settings (default provider, runs locally) ---
# Base URL for Ollama (defaults to http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434
# Model to use (defaults to llama3.2:latest)
# OLLAMA_MODEL=llama3.2:latest

# --- Anthropic Claude Settings ---
# Get your API key: https://console.anthropic.com/settings/keys
# Required if LLM_PROVIDER=claude
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# CLAUDE_MODEL=claude-sonnet-4-20250514

# --- Google Gemini Settings ---
# Get your API key: https://makersuite.google.com/app/apikey
# Required if LLM_PROVIDER=gemini
GOOGLE_API_KEY=your_google_api_key_here
# GEMINI_MODEL=gemini-1.5-flash

# ============================================================================
# OPTIONAL CONFIGURATION (all have defaults)
# See ../ENVIRONMENT.md for detailed explanations
# ============================================================================

# --- Conversation Memory Settings ---
# Maximum tokens before summarizing old messages (defaults to 2000)
# Higher values keep more context but use more tokens
# CONVERSATION_MAX_TOKEN_LIMIT=2000

# Whisper Model (optional, defaults to base)
# Options: tiny, base, small, medium, large
# See ../ENVIRONMENT.md for size and performance tradeoffs
# WHISPER_MODEL=base

# Whisper Device (optional, defaults to auto)
# Options: auto (use GPU if available), cuda (force GPU), cpu (force CPU)
# WHISPER_DEVICE=auto

# Development Mode (optional, defaults to false)
# When true, audio files are saved locally for debugging/testing
# WARNING: Only enable for development, not production
# DEVELOPMENT_MODE=false

# Audio Storage Path (optional, defaults to ./audio_files)
# Directory where audio files are saved in development mode
# AUDIO_STORAGE_PATH=./audio_files

# Server Configuration
HOST=127.0.0.1
PORT=8000

# Timezone Configuration (optional, defaults to Europe/Amsterdam)
# Common options: Europe/Amsterdam, Europe/Madrid, America/New_York, etc.
# See: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
TIMEZONE=Europe/Amsterdam

# Database
DATABASE_URL=sqlite+aiosqlite:///./babblr.db

# CORS Configuration (Frontend URL)
FRONTEND_URL=http://localhost:3000

# Debug settings
# DEVELOPMENT_MODE, for explicit checks e.g. for logging during development
# STT_DUMP_UPLOADS, stores the speech samples before upload for testing, e.g. speech to text
# DEVELOPMENT_MODE=false
# STT_DUMP_UPLOADS=false
