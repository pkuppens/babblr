# Docker Environment Configuration Template
# Copy this file to .env and configure with your values
# Usage: cp .env.docker .env

# ============================================
# LLM Provider Configuration
# ============================================
# Options: ollama, claude, gemini, mock
LLM_PROVIDER=ollama

# Ollama Configuration (for local LLM)
OLLAMA_MODEL=llama3.2:latest

# Claude API Configuration (if using LLM_PROVIDER=claude)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Gemini API Configuration (if using LLM_PROVIDER=gemini)
# Get your API key from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=

# ============================================
# Whisper STT Configuration
# ============================================
# Options: tiny, base, small, medium, large
# Larger models are more accurate but slower and use more memory
WHISPER_MODEL=large-v3

# ============================================
# Database Configuration (for production)
# ============================================
# Development uses PostgreSQL in Docker with these defaults:
# - User: babblr
# - Password: devpassword
# - Database: babblr
# - Host: postgres (Docker service name)
# - Port: 5432
#
# For production, override BABBLR_CONVERSATION_DATABASE_URL:
# BABBLR_CONVERSATION_DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/dbname
